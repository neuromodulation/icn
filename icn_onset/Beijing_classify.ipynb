{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_validate, GroupKFold, KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json_files(path):\n",
    "    \"\"\"Return individual paths to all data and events json files in given directory.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    path (string/path) : Path to directory where json files are located.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data_ (list) : Sorted list of all json data files\n",
    "    evs_ (list) : Sorted list of all json events files\n",
    "    \"\"\"\n",
    "    data_ = []\n",
    "    evs_ = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".json\"):\n",
    "                if file.startswith('evs'):\n",
    "                    evs_.append(os.path.join(root, file))\n",
    "                else:\n",
    "                    data_.append(os.path.join(root, file))\n",
    "    data_.sort()\n",
    "    evs_.sort()\n",
    "    return data_, evs_\n",
    "\n",
    "def concat_feats(X):\n",
    "    \"\"\"Concatenate data from 3-D array to 2-D array and transpose. Useful for using scikit classifiers.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    X (numpy array) : Array of shape (n_features, n_channels, n_samples).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Xm (numpy array) : Array of shape (n_samples, n_features*n_channels).\n",
    "    \"\"\"\n",
    "    feats = X.shape[0]\n",
    "    chans = X.shape[1]\n",
    "    samps = X.shape[2]\n",
    "    Xm = np.zeros((feats*chans,samps))\n",
    "    for chan in range(chans):\n",
    "        Xm[chan*feats:(chan+1)*feats,:] = X[:,chan,:]\n",
    "    Xm = Xm.T\n",
    "    return Xm\n",
    "\n",
    "def classify(X, labels, groups, lfp_chs, run):\n",
    "    \"\"\"Balance labels and classify with shrinkage LDA. Return 10-fold shuffled cross-val. mean-AP and accuracy.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    X (numpy array) : Array of shape (n_features, n_channels, n_samples). ECOG channels come first, LFP channels last.\n",
    "    labels (numpy array) : Array of labels of shape (n_samples). Must have same num. of samples as X.\n",
    "    lfp_chs (integer) : Number of LFP channels.\n",
    "    run (string) : Either 'All', 'All ECoG' or 'All LFP'. \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    mean_ap (float) : 10-fold cross validated mean_ap\n",
    "    accuracy (float) : Sorted list of all json events files\n",
    "    \"\"\"\n",
    "    if run == 'All':\n",
    "        Xm = concat_feats(X)\n",
    "    elif run == 'All ECoG':\n",
    "        Xm = concat_feats(X[:,0:-lfp_chs,:])\n",
    "    elif run == 'All LFP':\n",
    "        Xm = concat_feats(X[:,-lfp_chs:,:])\n",
    "    \n",
    "    df3 = pd.DataFrame(data=groups, columns=['group'])\n",
    "    df1 = pd.DataFrame(data=labels, columns=['label'])\n",
    "    df2 = pd.DataFrame(data=Xm)\n",
    "    df_join = df1.join([df2, df3])\n",
    "    value_counts = df_join['label'].value_counts()\n",
    "    df_majority = df_join[df_join.label==value_counts.index[0]]\n",
    "    df_minority = df_join[df_join.label==value_counts.index[1]]\n",
    "    df_maj_downsampled = resample(df_majority, replace=False, n_samples=len(df_minority))\n",
    "    df_downsampled = pd.concat([df_maj_downsampled, df_minority])\n",
    "    # Separate input features (X) and target variable (y)\n",
    "    y = df_downsampled.label\n",
    "    group = df_downsampled.group\n",
    "    X = df_downsampled.drop(['label','group'], axis=1)\n",
    "    clf = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "    #cv = KFold(n_splits = 5, shuffle=False)\n",
    "    cv = GroupKFold(n_splits=5)\n",
    "    scores = cross_validate(clf, X, y, cv=cv, groups=group, scoring=['average_precision', 'accuracy'])\n",
    "    mean_ap = round(np.mean(scores['test_average_precision']),3)\n",
    "    accuracy = round(np.mean(scores['test_accuracy']),3)\n",
    "    return mean_ap, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOG006\n",
      "FOG008\n",
      "FOG010\n",
      "FOG011\n",
      "FOG013\n",
      "FOGC001\n"
     ]
    }
   ],
   "source": [
    "inpath = '/Users/richardkoehler/OneDrive - Charité - Universitätsmedizin Berlin/BIDS Beijing derivatives/derivatives'\n",
    "outpath = inpath\n",
    "outfile = 'Beijing_LDA_scores.tsv'\n",
    "data_list, events_list = get_json_files(path=inpath)\n",
    "\n",
    "results = {}\n",
    "\n",
    "for ind, data in enumerate(data_list):\n",
    "    \n",
    "    with open(data_list[ind]) as json_file:\n",
    "        data_dict = json.load(json_file)\n",
    "    with open(events_list[ind]) as json_file:\n",
    "        events_dict = json.load(json_file)\n",
    "        \n",
    "    xf_zs_r = np.asarray(data_dict['data'])\n",
    "    subject = data_dict['subject']\n",
    "    print(subject)\n",
    "    labels = np.asarray(events_dict['labels'])\n",
    "    groups = np.asarray(events_dict['groups'])\n",
    "    \n",
    "    items = ['All', 'All ECoG', 'All LFP']\n",
    "    for item in items:\n",
    "        mean_ap, accuracy = classify(xf_zs_r, labels, groups, 6, item)\n",
    "        results.update({'Subject ' + subject + ' ' + item : [mean_ap,accuracy]})\n",
    "\n",
    "df = pd.DataFrame.from_dict(results,orient='index', columns=['MAP','Accuracy'])\n",
    "df.to_csv(os.path.join(outpath, outfile), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAP</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Subject FOG006 All</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject FOG006 All ECoG</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject FOG006 All LFP</th>\n",
       "      <td>0.697</td>\n",
       "      <td>0.672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject FOG008 All</th>\n",
       "      <td>0.472</td>\n",
       "      <td>0.461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject FOG008 All ECoG</th>\n",
       "      <td>0.438</td>\n",
       "      <td>0.444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject FOG008 All LFP</th>\n",
       "      <td>0.521</td>\n",
       "      <td>0.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject FOG010 All</th>\n",
       "      <td>0.743</td>\n",
       "      <td>0.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject FOG010 All ECoG</th>\n",
       "      <td>0.713</td>\n",
       "      <td>0.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject FOG010 All LFP</th>\n",
       "      <td>0.668</td>\n",
       "      <td>0.634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject FOG011 All</th>\n",
       "      <td>0.761</td>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject FOG011 All ECoG</th>\n",
       "      <td>0.691</td>\n",
       "      <td>0.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject FOG011 All LFP</th>\n",
       "      <td>0.552</td>\n",
       "      <td>0.535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject FOG013 All</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject FOG013 All ECoG</th>\n",
       "      <td>0.700</td>\n",
       "      <td>0.689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject FOG013 All LFP</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject FOGC001 All</th>\n",
       "      <td>0.853</td>\n",
       "      <td>0.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject FOGC001 All ECoG</th>\n",
       "      <td>0.851</td>\n",
       "      <td>0.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject FOGC001 All LFP</th>\n",
       "      <td>0.546</td>\n",
       "      <td>0.514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            MAP  Accuracy\n",
       "Subject FOG006 All        0.857     0.821\n",
       "Subject FOG006 All ECoG   0.841     0.827\n",
       "Subject FOG006 All LFP    0.697     0.672\n",
       "Subject FOG008 All        0.472     0.461\n",
       "Subject FOG008 All ECoG   0.438     0.444\n",
       "Subject FOG008 All LFP    0.521     0.490\n",
       "Subject FOG010 All        0.743     0.752\n",
       "Subject FOG010 All ECoG   0.713     0.715\n",
       "Subject FOG010 All LFP    0.668     0.634\n",
       "Subject FOG011 All        0.761     0.718\n",
       "Subject FOG011 All ECoG   0.691     0.688\n",
       "Subject FOG011 All LFP    0.552     0.535\n",
       "Subject FOG013 All        0.796     0.759\n",
       "Subject FOG013 All ECoG   0.700     0.689\n",
       "Subject FOG013 All LFP    0.796     0.710\n",
       "Subject FOGC001 All       0.853     0.825\n",
       "Subject FOGC001 All ECoG  0.851     0.832\n",
       "Subject FOGC001 All LFP   0.546     0.514"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
