import numpy as np
import rereference
import features_df

def run(gen, settings, df_M1):
    """Run "real-time" analysis of neurophysiological data generated by "gen".

    Parameters
    ----------
    gen : generator object
        generator that yields segments of data.
    settings : dict
        dictionary of settings such as "seglengths" or "frequencyranges"
    df_M1 : data frame
        data frame with the channel configurations and rereferencing settings.

    Returns
    -------
    features (df) : features defined as in settings
    """

    if isinstance(methods, str):
        methods = [methods]
    num_fbands = len(settings['frequencyranges'])
    num_features = num_fbands * len(methods)  # later important to be distinguishable for different features
    num_channels = df_M1[(df_M1["used"] == 1) & (df_M1["target"] == 0)].index.shape[0]
    feature_arr = np.zeros([1, num_channels, num_features])
    fs_new = int(settings["resamplingrate"])
    normalize_time = int(settings["normalization_time"])

    cnt_samples = 0

    if include_label:
        label = np.zeros(1)

    if normalize:
        normalize_samples = int(normalize_time * fs_new)
        feature_arr_norm = np.zeros(feature_arr.shape)
    while True:
        ieeg_batch = next(gen, None)
        if ieeg_batch is None:
            print(f"{str(np.round(cnt_samples/fs_new, 2))} seconds of data processed.")
            if normalize:
                return feature_arr_norm
            else:
                return feature_arr

        # separate label if included in data
        if include_label:
            current_label = ieeg_batch[-1, -1]
            ieeg_batch = ieeg_batch[0:-1, :]

        # call rereference
        ieeg_batch = preprocessing.rereference(ieeg_batch, df_M1)

        # calculate features
        feature_sample = features.get_features(ieeg_batch, settings, methods, fs, filter_fun)

        if cnt_samples == 0:
            feature_arr = np.expand_dims(feature_sample, axis=0)
            if include_label:
                label = np.reshape(current_label, (1,))
        else:
            feature_arr = np.concatenate((feature_arr, np.expand_dims(feature_sample, axis=0)), axis=0)
            if include_label:
                label = np.concatenate((label, np.reshape(current_label, (1,))))

        if normalize is True:
            if cnt_samples < normalize_samples:
                if cnt_samples == 0:
                    n_idx = 0
                else:
                    n_idx = np.arange(0, cnt_samples, 1)
            else:
                n_idx = np.arange(cnt_samples - normalize_samples, cnt_samples+1, 1)

            if cnt_samples == 0:
                feature_arr_norm = np.zeros(feature_arr.shape)
                feature_arr_norm[n_idx, :, :] = np.clip(feature_arr[n_idx, :, :], settings["clip_low"],
                                                        settings["clip_high"])
            else:
                if use_mean is True:
                    norm_previous = np.mean(feature_arr[n_idx, :, :], axis=0)
                else:
                    norm_previous = np.median(feature_arr[n_idx, :, :], axis=0)

                feature_norm = (feature_arr[cnt_samples, :, :] - norm_previous) / norm_previous

                # Artifact rejection
                feature_norm = np.clip(feature_norm, settings["clip_low"], settings["clip_high"])
                feature_arr_norm = np.concatenate((feature_arr_norm, np.expand_dims(feature_norm, axis=0)), axis=0)
        cnt_samples += 1
