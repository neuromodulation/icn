{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon May 18 17:55:08 2020\n",
    "\n",
    "@author: Pilin\n",
    "\"\"\"\n",
    "\n",
    "#%%\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import mne\n",
    "from mne.decoding import CSP\n",
    "from mne import Epochs\n",
    "from mne.decoding import SPoC\n",
    "mne.set_log_level(verbose='warning') #to avoid info at terminal\n",
    "import pickle\n",
    "import sys\n",
    "import IO\n",
    "import os\n",
    "import multiprocessing\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "#import tensorflow\n",
    "#import tensorflow as tf\n",
    "#import keras\n",
    "#from keras.layers import BatchNormalization\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense, Dropout\n",
    "#from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "#from keras.optimizers import Adam\n",
    "\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Permute, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import SpatialDropout2D\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "#from tensorflow.keras import backend as K\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "#from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "#from tensorflow.python.keras import backend as K\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "#from keras.callbacks import EarlyStopping\n",
    "#from keras.callbacks import ModelCheckpoint  did NOT work\n",
    "#from keras.models import load_model\n",
    "#from tensorflow.keras.layers import Dense, Activation, Permute, Dropout\n",
    "\n",
    "from scipy import stats\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import metrics\n",
    "from bayes_opt import BayesianOptimization\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "import gc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "VICTORIA = False\n",
    "WRITE_OUT_CH_IND = False\n",
    "USED_MODEL = 2 # 0 - Enet, 1 - XGB, 2 - NN\n",
    "settings = {}\n",
    "VERBOSE_ALL = 0\n",
    "\n",
    "if VICTORIA is True:\n",
    "    # insert at 1, 0 is the script path (or '' in REPL)\n",
    "    sys.path.insert(1, '/home/victoria/icn/icn_m1')\n",
    "    settings['BIDS_path'] = \"//mnt/Datos/BML_CNCRS/Data_BIDS_new/\"\n",
    "    settings['out_path'] = \"/mnt/Datos/BML_CNCRS/Data_processed/Derivatives/Raw_pipeline/\"\n",
    "    if USED_MODEL==0 :\n",
    "           settings['out_path_process'] = \"/mnt/Datos/BML_CNCRS/Spoc/ECoG_STN/LM_Out/\"\n",
    "    if USED_MODEL==1 :\n",
    "           settings['out_path_process'] = \"/mnt/Datos/BML_CNCRS/Spoc/ECoG_STN/XGB_Out/\"\n",
    "else:\n",
    "    settings['BIDS_path'] = \"C:\\\\Users\\\\ICN_admin\\\\Dropbox (Brain Modulation Lab)\\\\Shared Lab Folders\\\\CRCNS\\\\MOVEMENT DATA\\\\\"\n",
    "    settings['out_path'] = \"C:\\\\Users\\\\ICN_admin\\\\Dropbox (Brain Modulation Lab)\\\\Shared Lab Folders\\\\CRCNS\\\\MOVEMENT DATA\\\\derivatives\\\\Int_old_grid\\\\\"\n",
    "    settings['out_path_process'] = \"C:\\\\Users\\\\ICN_admin\\\\Dropbox (Brain Modulation Lab)\\\\Shared Lab Folders\\\\CRCNS\\MOVEMENT DATA\\\\ECoG_STN\\\\NN_Out\\\\\"\n",
    "\n",
    "settings['frequencyranges']=[[4, 8], [8, 12], [13, 20], [20, 35], [13, 35], [60, 80], [90, 200], [60, 200]]\n",
    "settings['seglengths']=[1, 2, 2, 3, 3, 3, 10, 10, 10]\n",
    "settings['num_patients']=['000', '001', '004', '005', '006', '007', '008', '009', '010', '013', '014']\n",
    "settings['BIDS_path']=settings['BIDS_path'].replace(\"\\\\\", \"/\")\n",
    "settings['out_path']=settings['out_path'].replace(\"\\\\\", \"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test 1: does pool_function_la run through? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_NN(learning_rate, num_dense_layers, num_input_nodes, num_dense_nodes, activation):\n",
    "        \"\"\"\n",
    "        Create NN tensorflow with different numbers of hidden layers / hidden units\n",
    "        \"\"\"\n",
    "\n",
    "        #start the model making process and create our first layer\n",
    "        model = tensorflow.keras.Sequential()\n",
    "        model.add(Dense(num_input_nodes, input_shape=(40,), activation=activation))\n",
    "\n",
    "        #create a loop making a new dense layer for the amount passed to this model.\n",
    "        #naming the layers helps avoid tensorflow error deep in the stack trace.\n",
    "        for i in range(num_dense_layers):\n",
    "            name = 'layer_dense_{0}'.format(i+1)\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(Dense(num_dense_nodes,\n",
    "                     activation=activation,\n",
    "                            name=name\n",
    "                     ))\n",
    "        #add our classification layer.\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(1,activation='linear'))\n",
    "\n",
    "        #setup our optimizer and compile\n",
    "        adam = Adam(lr=learning_rate)\n",
    "        model.compile(optimizer=adam, loss='mean_squared_error',\n",
    "                     metrics=['mse'])\n",
    "        return model\n",
    "\n",
    "\n",
    "def append_time_dim(arr, y_, time_stamps):\n",
    "    \"\"\"\n",
    "    apply added time dimension for the data array and label given time_stamps (with downsample_rate=100) in 100ms / need to check with 1375Hz\n",
    "    \"\"\"\n",
    "    time_arr = np.zeros([arr.shape[0]-time_stamps, int(time_stamps*arr.shape[1])])\n",
    "    for time_idx, time_ in enumerate(np.arange(time_stamps, arr.shape[0])):\n",
    "        for time_point in range(time_stamps):\n",
    "            time_arr[time_idx, time_point*arr.shape[1]:(time_point+1)*arr.shape[1]] = arr[time_-time_point,:]\n",
    "    return time_arr, y_[time_stamps:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_function_la(X, label, ch_idx, laterality_, signal_, subfolder, sess_idx, sub_idx):\n",
    "\n",
    "    Ypre_te= []\n",
    "    Ypre_tr= []\n",
    "    score_tr= []\n",
    "    Ypre_te= []\n",
    "    score_te= []\n",
    "    label_test=[]\n",
    "    label_train=[]\n",
    "    coords = []\n",
    "    coef_ = []\n",
    "    hyp_=[]\n",
    "    for train_index, test_index in cv.split(X):\n",
    "        Xtr, Xte=X[train_index,:], X[test_index,:]\n",
    "        Ytr, Yte=label[train_index], label[test_index]\n",
    "        label_test.append(Yte)\n",
    "        label_train.append(Ytr)\n",
    "        dat_tr,label_tr = append_time_dim(Xtr, Ytr, time_stamps=5)\n",
    "        dat_te,label_te = append_time_dim(Xte, Yte, time_stamps=5)\n",
    "\n",
    "        if USED_MODEL == 0: # Enet\n",
    "            optimizer=optimize_enet(x=dat_tr,y=label_tr)\n",
    "            model=ElasticNet(alpha=optimizer['x'][0],\n",
    "                               l1_ratio=optimizer['x'][1],\n",
    "                               max_iter=1000,\n",
    "                               normalize=False)\n",
    "        elif USED_MODEL == 1: # XGB\n",
    "            optimizer=optimize_xgb(x=dat_tr, y=label_tr)\n",
    "            model=XGBRegressor(max_depth=optimizer['x'][0],\n",
    "                               learning_rate=optimizer['x'][1],\n",
    "                               gamma=optimizer['x'][2], subsample= 0.8,\n",
    "                               eta= 0.1,\n",
    "                               disable_default_eval_metric= 1)\n",
    "\n",
    "        elif USED_MODEL == 2:\n",
    "            try:\n",
    "                #optimizer = optimize_nn(dat_tr, label_tr, ch_idx, laterality_)\n",
    "                optimizer = {}\n",
    "                optimizer['x'] = {}\n",
    "                optimizer['x'][0] = 0.01\n",
    "                optimizer['x'][1] = 1\n",
    "                optimizer['x'][2] = 2\n",
    "                optimizer['x'][3] = 2\n",
    "                optimizer['x'][4] = \"tanh\"\n",
    "            except:\n",
    "                print(\"INF / NAN ERROR\")\n",
    "                continue\n",
    "            learning_rate=optimizer['x'][0]\n",
    "            num_dense_layers=optimizer['x'][1]\n",
    "            num_input_nodes=optimizer['x'][2]\n",
    "            num_dense_nodes=optimizer['x'][3]\n",
    "            activation=optimizer['x'][4]\n",
    "            model = create_model_NN(learning_rate, num_dense_layers, num_input_nodes, num_dense_nodes, activation)\n",
    "        else:\n",
    "            break\n",
    "            print(\"ARCHITECTURE IS NOT DEFINED\")\n",
    "\n",
    "        if USED_MODEL == 2:\n",
    "\n",
    "            es = EarlyStopping(monitor='val_mse', mode='min', verbose=VERBOSE_ALL, patience=10)\n",
    "            mc = ModelCheckpoint('best_model.h5', monitor='val_mse', mode='min', verbose=VERBOSE_ALL, save_best_only=True)\n",
    "            X_train, X_val, y_train, y_val = train_test_split(dat_tr, label_tr, train_size=0.8,shuffle=True)\n",
    "            model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=1000, batch_size=100, verbose=VERBOSE_ALL, callbacks=[mc,es])\n",
    "            r2_tr = metrics.r2_score(model.predict(X_train), y_train)\n",
    "            if r2_tr < 0: r2_tr = 0\n",
    "            r2_te = metrics.r2_score(model.predict(dat_te), label_te)\n",
    "            print(\"channel: \"+str(ch_idx)+\" r2 test: \"+str(r2_te))\n",
    "            if r2_te < 0: r2_te = 0\n",
    "\n",
    "        else:\n",
    "            model.fit(dat_tr, label_tr)\n",
    "            r2_tr=model.score(dat_tr, label_tr)\n",
    "            if r2_tr < 0: r2_tr = 0\n",
    "            r2_te=model.score(dat_te, label_te)\n",
    "            if r2_te < 0: r2_te = 0\n",
    "\n",
    "        score_tr.append(r2_tr)\n",
    "        score_te.append(r2_te)\n",
    "        #with tf.device(tf.DeviceSpec(device_type=\"CPU\", device_index=0)):\n",
    "        Ypre_te.append(model.predict(dat_te) if USED_MODEL != 2 else model.predict(dat_te)[:,0])\n",
    "        Ypre_tr.append(model.predict(dat_tr) if USED_MODEL != 2 else model.predict(dat_tr)[:,0])\n",
    "        if USED_MODEL == 0: coef_.append(model.coef_)\n",
    "        hyp_.append(optimizer['x'])\n",
    "\n",
    "    Score_tr=np.mean(score_tr)\n",
    "    Score_te=np.mean(score_te)\n",
    "    Label_te=label_test\n",
    "    Label_tr=label_train\n",
    "    Labelpre_te=Ypre_te\n",
    "    Labelpre_tr=Ypre_tr\n",
    "    COEF_=coef_\n",
    "    Hyperarapms=hyp_\n",
    "\n",
    "    predict_ = {\n",
    "        \"y_pred_test\": Ypre_te,\n",
    "        \"y_test\": Label_te,\n",
    "        \"y_pred_train\": Ypre_tr,\n",
    "        \"y_train\": Label_tr,\n",
    "        \"score_tr\": Score_tr,\n",
    "        \"score_te\": Score_te,\n",
    "        #\"coord_patient\" : run_[\"coord_patient\"],\n",
    "        \"coef\" :coef_,\n",
    "        \"model_hyperparams\": hyp_\n",
    "    }\n",
    "\n",
    "    out_path_file = os.path.join(settings['out_path_process']+ \\\n",
    "        settings['num_patients'][sub_idx]+'BestChpredictions_'+\\\n",
    "        signal_+'-ch-'+str(ch_idx)+'-lat-'+str(laterality_)+'-'+str(subfolder[sess_idx])+'.npy')\n",
    "    np.save(out_path_file, predict_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.random([1000,8])\n",
    "label = np.arange(1000)\n",
    "ch_idx = 0\n",
    "laterality_ = \"CON\"\n",
    "signal_ = \"ECOG\"\n",
    "subfolder = [\"right\"]\n",
    "sess_idx = 0\n",
    "sub_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel: 0 r2 test: -459747.93160811736\n",
      "channel: 0 r2 test: -6.120615195640106\n",
      "channel: 0 r2 test: -22.600996426363935\n"
     ]
    }
   ],
   "source": [
    "pool_function_la(X, label, ch_idx, laterality_, signal_, subfolder, sess_idx, sub_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rewrite getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_int_runs(subject_id, subfolder):\n",
    "    \"\"\"\n",
    "\n",
    "    :param patient_idx:\n",
    "    :return: list with all run files for the given patient\n",
    "    \"\"\"\n",
    "    os.listdir(settings['out_path'])\n",
    "\n",
    "    if 'right' in str(subfolder):\n",
    "        list_subject = [i for i in os.listdir(settings['out_path']) if i.startswith('sub_'+subject_id+'_sess_right') and i.endswith('.p')]\n",
    "    else:\n",
    "        list_subject = [i for i in os.listdir(settings['out_path']) if i.startswith('sub_'+subject_id+'_sess_left') and i.endswith('.p')]\n",
    "\n",
    "    return list_subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=3, shuffle=False)\n",
    "laterality=[(\"CON\"), (\"IPS\")]\n",
    "signal=[\"ECOG\", \"STN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_data():\n",
    "    \n",
    "    for sub_idx in np.arange(0, len(settings['num_patients']), 1):\n",
    "        list_param = [] # list for pool\n",
    "        for signal_idx, signal_ in enumerate(signal):\n",
    "            subject_path=settings['BIDS_path'] + 'sub-' + settings['num_patients'][sub_idx]\n",
    "            subfolder=IO.get_subfolders(subject_path)\n",
    "\n",
    "            for sess_idx in range(len(subfolder)):\n",
    "                if os.path.exists(os.path.join(settings['out_path_process'],\n",
    "                            settings['num_patients'][sub_idx]+'BestChpredictions_'+signal_+'-'+\n",
    "                                str(subfolder[sess_idx])+'.npy')) is True:\n",
    "                    continue\n",
    "                X=[]\n",
    "                Y_con=[]\n",
    "                Y_ips=[]\n",
    "                list_subject=get_int_runs(settings['num_patients'][sub_idx], subfolder[sess_idx])\n",
    "                list_subject=sorted(list_subject)\n",
    "                if signal_==\"ECOG\":\n",
    "                    if sub_idx==4 and sess_idx==0: #for sake of comparison with spoc\n",
    "                        list_subject.pop(0)\n",
    "                    if sub_idx==4 and sess_idx==1:\n",
    "                        list_subject.pop(2)\n",
    "\n",
    "                print('RUNNIN SUBJECT_'+ settings['num_patients'][sub_idx]+ '_SESS_'+ str(subfolder[sess_idx]) + '_SIGNAL_' + signal_)\n",
    "                for run_idx in range(len(list_subject)):\n",
    "                    with open(settings['out_path']+ '/'+ list_subject[run_idx], 'rb') as handle:\n",
    "                        run_ = pickle.load(handle)\n",
    "\n",
    "                    #concatenate features\n",
    "                    #get cortex data only\n",
    "                    if signal_==\"ECOG\":\n",
    "                        ind_cortex=run_['used_channels']['cortex']\n",
    "                        rf=run_['rf_data_median']\n",
    "                        x=rf[:,ind_cortex,:]\n",
    "                        x=np.clip(x, -2,2) # this should have been implemented in the pipeline\n",
    "                        y=run_['label_baseline_corrected']\n",
    "                        con_true=run_['label_con_true']\n",
    "                        y_con=np.squeeze(y[con_true==True])\n",
    "                        y_ips=np.squeeze(y[con_true==False])\n",
    "                        X.append(x)\n",
    "                        Y_con.append(y_con)\n",
    "                        Y_ips.append(y_ips)\n",
    "                    else:\n",
    "                        ind_subcortex=run_['used_channels']['subcortex']\n",
    "                        if ind_subcortex is not None:\n",
    "\n",
    "                            rf=run_['rf_data_median']\n",
    "                            x=rf[:,ind_subcortex,:]\n",
    "                            x=np.clip(x, -2,2)\n",
    "\n",
    "                            y=run_['label_baseline_corrected']\n",
    "                            con_true=run_['label_con_true']\n",
    "                            y_con=np.squeeze(y[con_true==True])\n",
    "                            y_ips=np.squeeze(y[con_true==False])\n",
    "\n",
    "                            X.append(x)\n",
    "                            Y_con.append(y_con)\n",
    "                            Y_ips.append(y_ips)\n",
    "\n",
    "                gc.collect() # free unreferenced memory\n",
    "                X=np.concatenate(X, axis=0)\n",
    "                Y_con=np.concatenate(Y_con, axis=0)\n",
    "                Y_ips=np.concatenate(Y_ips, axis=0)\n",
    "\n",
    "                for laterality_idx, laterality_ in enumerate(laterality):\n",
    "                    for ch_idx in range(X.shape[1]):\n",
    "                        if laterality_ == \"CON\":\n",
    "                            label_here = Y_con\n",
    "                        else:\n",
    "                            label_here = Y_ips\n",
    "                        yield X[:,ch_idx,:], label_here, ch_idx, laterality_, signal_, subfolder, sess_idx, sub_idx\n",
    "                        #list_param.append((X[:,ch_idx,:], label_here, ch_idx, laterality_, signal_, subfolder, sess_idx, sub_idx))\n",
    "        #pool = multiprocessing.Pool(len(list_param))\n",
    "        #pool.starmap(pool_function_la, list_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ses-right\n",
      "RUNNIN SUBJECT_000_SESS_ses-right_SIGNAL_ECOG\n"
     ]
    }
   ],
   "source": [
    "patient_dat_generator = get_patient_data()\n",
    "l_all.append(next(patient_dat_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_all.append(next(patient_dat_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "break at i=60\n",
      "and back\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while True:\n",
    "    i +=1\n",
    "    if (i % 60) == 0:\n",
    "        print(\"break at i=\"+str(i))\n",
    "        break\n",
    "print(\"and back\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"C:\\\\Users\\\\ICN_admin\\\\Dropbox (Brain Modulation Lab)\\\\Shared Lab Folders\\\\CRCNS\\MOVEMENT DATA\\\\ECoG_STN\\\\NN_Out\\\\006BestChpredictions_ECOG-ch-35-lat-IPS-ses-left.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({'y_pred_test': [array([0.09022155, 0.03381903, 0.0220023 , ..., 0.10388179, 0.10783441,\n",
       "       0.10616177], dtype=float32), array([0.12789677, 0.12744671, 0.12647632, ..., 0.02634905, 0.1228833 ,\n",
       "       0.12344892], dtype=float32), array([0.15403625, 0.15235761, 0.14889506, ..., 0.00866455, 0.00838803,\n",
       "       0.00810571], dtype=float32)], 'y_test': [array([0., 0., 0., ..., 0., 0., 0.]), array([0., 0., 0., ..., 0., 0., 0.]), array([0.26174359, 0.55743707, 0.80283973, ..., 0.        , 0.        ,\n",
       "       0.        ])], 'y_pred_train': [array([0.10394712, 0.10463816, 0.10486241, ..., 0.00895429, 0.00917452,\n",
       "       0.00871366], dtype=float32), array([0.01110069, 0.0103773 , 0.00982634, ..., 0.01031327, 0.00904689,\n",
       "       0.00845811], dtype=float32), array([0.02468543, 0.00946013, 0.00825727, ..., 0.04918476, 0.03546977,\n",
       "       0.02947852], dtype=float32)], 'y_train': [array([0., 0., 0., ..., 0., 0., 0.]), array([0., 0., 0., ..., 0., 0., 0.]), array([0., 0., 0., ..., 0., 0., 0.])], 'score_tr': 0.0, 'score_te': 0.0, 'coef': [], 'model_hyperparams': [[0.0015335192657991573, 3, 9, 9, 'tanh'], [0.0015335192657991573, 3, 9, 9, 'tanh'], [0.0015335192657991573, 3, 9, 9, 'tanh']]},\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(PATH, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path_file = os.path.join(settings['out_path_process']+ \\\n",
    "                            settings['num_patients'][sub_idx]+'BestChpredictions_'+\\\n",
    "                            signal_+'-ch-'+str(ch_idx)+'-lat-'+str(laterality_)+'-'+str(subfolder[sess_idx])+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ICN_admin\\\\Dropbox (Brain Modulation Lab)\\\\Shared Lab Folders\\\\CRCNS\\\\MOVEMENT DATA\\\\ECoG_STN\\\\NN_Out\\\\000BestChpredictions_ECOG-ch-0-lat-CON-right.npy'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_path_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JA\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(PATH) is True:\n",
    "    print(\"JA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
